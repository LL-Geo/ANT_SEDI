---
title: "Subglacial sedimentary basins focus key vulnerabilities of the Antarctic ice-sheet"
author:
- affiliation:  "School of Earth Sciences, The University Of Western Australia, Perth WA, Australia"
  name: "Lu Li^1*, Alan R.A. Aitken^12, Mark D. Lindsay^134, Bernd Kulessa^56"
licenses:
  code: CC-BY-3.0
  data: CC-BY-3.0
  text: CC-BY-3.0
output:
  html_document:
    toc: yes
params:
  useCache: TRUE
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
knitr::opts_chunk$set(comment = "")
```

# Introduction

A map of distribution of subglacial sedimentary basin of Antarctica is driven from the current understanding of Antarctica bedrock type and continental scale geophysical datasets. The training points are generated by sparse bedrock outcrop, seismic imaging, and geophysical interpretation. Evidence layers including continental scale topography, gravity, magnetic, and their derivative products.  

# Preparation

## Load required R packages

The required R pacages are loaded.
```{r packages, echo=TRUE}
suppressPackageStartupMessages({
library(geosphere)
library(sdmpredictors)
library(randomForest)
library(summarytools)
library(Boruta)
library(caret)
library(raster)
library(ggplot2)
library(GGally)
library(rgdal)
library(corrplot)
library(blockCV)
library(measures)
library(reticulate)
library(readr)
library(missForest)
library(sf)
library(Hmisc)
library(gapfill)
library(colorRamps)
library(scico)
library(MLeval)
library(precrec)
library(rgeos)
library(VIM)
library(mice)
library(minerva)
library(ggpubr)
library(viridis)
library(fields)
library(reshape)

})
```


## Define function to train the model
```{r,echo=TRUE}
sample_training <- function(Train,Evidence,fishgrid,mtry,ntree,ns,nk,seed) {

rgeos::set_RGEOS_CheckValidity(2L)


Train_Basement <- subset(Train, Label == 0)

Train_SSB <- subset(Train, Label == 1)

Train_Basement_M <- aggregate(Train_Basement,dissolve=T)

Train_SSB_M <- aggregate(Train_SSB,dissolve=T)

Train_Basement_M_C <- gIntersection(Train_Basement_M, fishgrid, byid = TRUE, drop_lower_td = T)

Train_SSB_M_C <- gIntersection(Train_SSB_M, fishgrid, byid = TRUE, drop_lower_td = T)

Train_Basement.sp <- SpatialPolygonsDataFrame(Train_Basement_M_C, data.frame(N = c(1:length(Train_Basement_M_C))), match.ID = F) 

Train_SSB.sp <- SpatialPolygonsDataFrame(Train_SSB_M_C, data.frame(N = c(1:length(Train_SSB_M_C))), match.ID = F)


prob.all <- stack()

fres.all <- stack()

Model_Validation <- list()

T.all <- list()

bcv.all <- data.frame()

bcv.acc <- list()

for (k in 1:nk) {

set.seed(seed[k]) #Set seed for reproducibility
  
  
T_base <- list()

T_basin <- list()


for (i in unique(Train_Basement.sp$N)) {
        HR <- Train_Basement.sp[Train_Basement.sp$N==i,]
        T_base[[i]] <- spsample(HR, n = ns, "random",iter=10)
}


for (i in unique(Train_SSB.sp$N)) {
        HR <- Train_SSB.sp[Train_SSB.sp$N==i,]
        T_basin[[i]] <- spsample(HR, n = ns, "random",iter=10)
}

Tbase <- do.call("rbind", T_base)
Tbasin <- do.call("rbind", T_basin)


# Label training points
Tbase$Label <- c(1:length(Tbase))

Tbase$Label <- 0

Tbasin$Label <- c(1:length(Tbasin))

Tbasin$Label <- 1

TB <- rbind(Tbase,Tbasin)


# Extract Evidence Layers Information into Training Point

sdata <- data.frame(TB,extract(Evidence,TB))

sdata <- sdata[-c(4)]

names(sdata)[2] <- "x"

names(sdata)[3] <- "y"



sdata <- na.omit(sdata) #drop nan value

data_min <- min(table(sdata$Label))

data_min <- min(data_min,613)


sub_0 <- sample( nrow(subset(sdata, Label == 0 )), data_min)
sub_1 <- sample( nrow(subset(sdata, Label == 1 )), data_min)

sdata_s_0 <- subset(sdata, Label == 0 )[sub_0, ]
sdata_s_1 <- subset(sdata, Label == 1 )[sub_1, ]

sdata <- rbind(sdata_s_0,sdata_s_1)


if (k==1) {
TPSummary <- data.frame(sdata[1:3])
} else {
TPSummary <- data.frame(TPSummary,sdata[1:3])
}



TP <- st_as_sf(sdata, coords = c("x", "y"), crs = 3031) 

TP.s <- as(TP, "Spatial")

tp_nb <- st_set_geometry(TP, NULL) #remove geometry

tp_ngeo <- tp_nb

tp_in <- na.omit(tp_ngeo) #drop nan value


#Fit a model

  
tp_in$Label <- as.factor(tp_in$Label)


fit <- randomForest(Label ~ ., data=tp_in, ntree=ntree, mtry=mtry, replace = T, importance = TRUE,na.action = na.roughfix)


#Variable importance
randomForest::importance(fit, type=1, scale = FALSE) #table

main <- paste("Variable Importance on TP",nk)

I1 <- ++ varImpPlot(fit, type=1, scale = FALSE) #plot

if (k==1) {
I2 <- data.frame(I1)
} else {
  I2 <- data.frame(I2,I1)
}


class <- c("0","1")

classes <- c("Basement","SSB")


#Predicted probabilities

rfprob <- predict(Evidence, fit, type="prob", index=class)




names(rfprob) <- classes

prob.all <- stack(prob.all,rfprob$SSB)

max.prob <- max(rfprob)
max.prob

rfres <- predict(Evidence, fit, type="response")

fres.all <- stack(fres.all,rfres)


levels(tp_in$Label) <- c("Basement", "SSB")




pred_T <- predict(fit, tp_in, type = "response") # predict the test set

Predit_Train <- rbind(data.frame(tp_in[,1], pred_T, sdata[,2:3]))  

T.all <- rbind(T.all,Predit_Train)



#Perform Block Cross Validation
block.C2 <- spatialBlock(speciesData = TB, # sf or SpatialPoints
                   species = "label", # the response column (binomial or multi-class)
                   rows = 10,
                   cols = 10,
                   k = 10, # number of folds
                   selection = "random")  
                   
folds <- block.C2$folds

Nclasses <- c(2L)

class <- c("0","1")

classes <- c("Basement","SSB")
  
# create a data.frame to store the prediction of each fold (record)
testTable <- tp_in
testTable$pred <- NA

t <- data.frame()
  
  
for(kk in seq_len(length(folds))){
  
  # extracting the training and testing indices
  # this way works with folds list (but not foldID)
  trainSet <- unlist(folds[[kk]][1]) # training set indices
  
  testSet <- unlist(folds[[kk]][2]) # testing set indices
  
  sub_train <- tp_in[trainSet, ]
  
  sub_train$Label <- as.factor(sub_train$Label)
    
  sub_test <- tp_in[testSet, ]
  
  nnmin <- min(table(sub_train[1]))
  
  rf <- randomForest(Label~., data=sub_train, replace = T, ntree=ntree, mtry=mtry, na.action = na.roughfix) # model fitting on training set
  
  pred <- predict(rf, sub_test, type = "response",na.action = na.roughfix) # predict the test set
  
  t <- rbind(t, data.frame(sub_test[1], pred, sdata[testSet,2:3]))
  
}


acc <- confusionMatrix(t$pred,as.factor(t$Label))

name <- paste("T", kk, sep = "")

tmp <- list(conf=acc)
  
bcv.acc[[name]] <- tmp

bcv.all <- rbind(bcv.all,t)



}

Result <- list("TP"=TPSummary,"Probalility" = prob.all,"fress"= fres.all,"importance"=I2,"TPacc"=T.all,"blockCV"=bcv.all,"blockacc"=bcv.acc)

return (Result)
}

```


```{r,echo=TRUE}
sampling <- function(Train,Evidence,fishgrid,ns,nk,seed) {

  rgeos::set_RGEOS_CheckValidity(2L)

for (k in 1:nk) {

  set.seed(seed[k]) #Set seed for reproducibility

Train_Basement <- subset(Train, Label == 0)

Train_SSB <- subset(Train, Label == 1)

Train_Basement_M <- aggregate(Train_Basement,dissolve=T)

Train_SSB_M <- aggregate(Train_SSB,dissolve=T)

Train_Basement_M_C <- gIntersection(Train_Basement_M, fishgrid, byid = TRUE, drop_lower_td = T)

Train_SSB_M_C <- gIntersection(Train_SSB_M, fishgrid, byid = TRUE, drop_lower_td = T)

Train_Basement.sp <- SpatialPolygonsDataFrame(Train_Basement_M_C, data.frame(N = c(1:length(Train_Basement_M_C))), match.ID = F) 

Train_SSB.sp <- SpatialPolygonsDataFrame(Train_SSB_M_C, data.frame(N = c(1:length(Train_SSB_M_C))), match.ID = F)


prob.all <- stack()

fres.all <- stack()



T_base <- list()

T_basin <- list()


for (i in unique(Train_Basement.sp$N)) {
        HR <- Train_Basement.sp[Train_Basement.sp$N==i,]
        T_base[[i]] <- spsample(HR, n = ns, "random",iter=10)
}


for (i in unique(Train_SSB.sp$N)) {
        HR <- Train_SSB.sp[Train_SSB.sp$N==i,]
        T_basin[[i]] <- spsample(HR, n = ns, "random",iter=10)
}

Tbase <- do.call("rbind", T_base)
Tbasin <- do.call("rbind", T_basin)


# Label training points
Tbase$Label <- c(1:length(Tbase))

Tbase$Label <- 0

Tbasin$Label <- c(1:length(Tbasin))

Tbasin$Label <- 1

TB <- rbind(Tbase,Tbasin)


# Extract Evidence Layers Information into Training Point

sdata <- data.frame(TB,extract(Evidence,TB))

sdata <- sdata[-c(4)]

names(sdata)[2] <- "x"

names(sdata)[3] <- "y"

data_min <- min(table(sdata$Label))

print(table(sdata$Label))

data_min <- min(data_min,613)


sub_0 <- sample( nrow(subset(sdata, Label == 0 )), data_min)
sub_1 <- sample( nrow(subset(sdata, Label == 1 )), data_min)

sdata_s_0 <- subset(sdata, Label == 0 )[sub_0, ]
sdata_s_1 <- subset(sdata, Label == 1 )[sub_1, ]

sdata <- rbind(sdata_s_0,sdata_s_1)


TP <- st_as_sf(sdata, coords = c("x", "y"), crs = 3031) 

TP <- as(TP, "Spatial")

if (k==1) {
TP.s <- TP
} else {
TP.s <- rbind(TP.s,TP)
}

}
return (TP.s)
}


```

## Load shapefiles for mapping

The coastline and major ice catchments are loaded
```{r, echo=TRUE}

Coastline <- readOGR("Coastline_Antarctica_v02.shp")

Basins_IMBIE <- readOGR("Basins_IMBIE_Antarctica_v02.shp")

crs(Coastline)

crs(Basins_IMBIE)


```


# Training point

Training points are generated based on bedrock outcrop, seismic imaging, and potential filed data interpertation

## Read the Training Shapefile and the fishnet to sub sampling training point

```{r,echo=TRUE}

Train_poly <- readOGR("SSB_shapefile8_c.shp")

fishgrid <- readOGR("TP_fish.shp")

fishgrids <- readOGR("TP_fish_shift.shp")

fishgrid_200 <- readOGR("TP_fish_20k.shp")


DataDensity <- readOGR("Kernal_F5.shp")

```

Edit and divide training polygon into sedimentary basin (Label:1) and crystalline rock (Label:0)

```{r,echo=TRUE}

Train_select <- Train_poly

Train_select[Train_poly$Id == 1] <- 1 #Seismic
Train_select[Train_poly$Id ==  0] <- 0

#Train_select[Train_poly$Id ==  110] <- 5


Train_select[Train_select$Label ==2] <-0 #Old SSB

#Train_select[Train_select$Id ==4] <-1


Train_select <- subset(Train_select, Label < 3)


Train_Basement <- subset(Train_select, Label == 0)

Train_SSB <- subset(Train_select, Label == 1)
```

## Plot Training Polygon

Blue for basement rock, red for sedimentary basin
```{r ,echo=TRUE,fig.width=6, fig.height=6}

plot(x=NULL,
      y=NULL,
      xlim=c(-2705000, 2815000),  ## with c()
      ylim=c(-2315000, 2215000),xlab="X/m", ylab="Y/m",
      asp=1)  ## with c()
plot(Train_Basement,add=T,col="blue")
plot(Train_SSB,add=T,col="red")
plot(Basins_IMBIE,add=T)

plot(fishgrid,add=T)
legend("topright",
       legend = c('Basement', 'Sedimentary Basin'),
       fill = c("blue","red"),       # Color of the squares
       border = "black") # Color of the border of the squares
```


# Evidence layers

The evidence layers is generated from avaiLabel continental scale geophysical datasets. Including, bedrock topography, gravity, magnetic.


## Read the Evidence layers

Read evidence layers into a spatial data frame
```{r}

my_shape <- readOGR("Extend.shp")



fs <- list.files(path="C:\\Users\\22528618\\Desktop\\SSB_Review\\FF_Evidence", pattern = ".ers$", full.names = TRUE)


for (i in 1:length(fs)) {
  HR <- raster(fs[i])
  HRC <- crop(HR, extent(my_shape)) ### crop to the extent
  HRCM <- raster::mask(HRC, my_shape)
  HRCM[is.na(HRCM[])] <- cellStats(HRCM, 'mean')
  if (i==1) {
    S <- stack(HRCM)
  } else {
    S <- stack(S,HRCM)
  }
}

S <- raster::mask(S, my_shape)

Predp.stark <- S

```


## Plot Evidence layers


```{r ,echo=TRUE,fig.width=12, fig.height=12}
par(mfrow=c(3,3),mar=c(2, 2, 2, 6))    # set the plotting area into a 1*2 array

sel <- subset(Predp.stark,1:9)

le_text=c("nT/m","nT","nT*m","nT*m","nT","nT","km","mGal","mGal")
for (i in 1:9) {
  
plot(sel[[i]], col=plasma(21),asp=1,main=names(sel)[i],legend.args =list(text=le_text[i]))
plot(Basins_IMBIE,add=T)
plot(Coastline,add=T)

}


```

```{r ,echo=TRUE,fig.width=12, fig.height=12}
par(mfrow=c(3,3),mar=c(2, 2, 2, 6))    # set the plotting area into a 1*2 array

sel <- subset(Predp.stark,10:18)

le_text=c("mGal","mGal","mGal","mGal","mGal","mGal","mGal","kPa","km")
for (i in 1:9) {
  
plot(sel[[i]], col=plasma(21),asp=1,main=names(sel)[i],legend.args =list(text=le_text[i]))
plot(Basins_IMBIE,add=T)
plot(Coastline,add=T)

}


```


```{r ,echo=TRUE,fig.width=12, fig.height=9}
par(mfrow=c(2,3),mar=c(2, 2, 2, 6))    # set the plotting area into a 1*2 array

sel <- subset(Predp.stark,19:length(fs))

le_text=c("mW/m^2","m/a","","m","m","")

for (i in 1:1) {
  
plot(sel[[i]], col=plasma(21),asp=1,main=names(sel)[i],legend.args =list(text=le_text[i]))
plot(Basins_IMBIE,add=T)
plot(Coastline,add=T)

}

cuts=c(0,1,10,30,50,100,1000,2000,4000) #set breaks
plot(sel[[2]], col=plasma(10),breaks=cuts, asp=1,main=names(sel)[2],legend.args =list(text=le_text[2]))
plot(Basins_IMBIE,add=T)
plot(Coastline,add=T)


for (i in 3:6) {
  
plot(sel[[i]], col=plasma(21),asp=1,main=names(sel)[i],legend.args =list(text=le_text[i]))
plot(Basins_IMBIE,add=T)
plot(Coastline,add=T)

}



```


# Evidence layer selection and RF parameter turning

## Sample to generate training points

```{r ,echo=TRUE,include=FALSE}

seed=1

TP_example <- sampling(Train_select,Predp.stark,fishgrid,1,1,seed)


```


Plot training points

```{r ,echo=TRUE,fig.width=12, fig.height=6}
par(mfrow=c(1,2))    # set the plotting area into a 1*2 array

plot(x=NULL,
      y=NULL,
      xlim=c(-2705000, 2815000),  ## with c()
      ylim=c(-2315000, 2215000),xlab="X/m", ylab="Y/m",main="Training polygon",
      asp=1)  ## with c()
plot(Train_Basement,add=T,col="blue")
plot(Train_SSB,add=T,col="red")
plot(Basins_IMBIE,add=T)
plot(Coastline,add=T)

plot(fishgrid,add=T)
legend("topright",
       legend = c('Basement', 'Sedimentary Basin'),
       fill = c("blue","red"),       # Color of the squares
       border = "black") # Color of the border of the squares

plot(x=NULL,
      y=NULL,
      xlim=c(-2705000, 2815000),  ## with c()
      ylim=c(-2315000, 2215000),xlab="X/m", ylab="Y/m",main="Training points",
      asp=1)  ## with c()

plot(TP_example[TP_example@data[["Label"]]==1,],col="red",pch=16,add=T,cex=0.4)
plot(TP_example[TP_example@data[["Label"]]==0,],col="blue",pch=16,add=T,cex=0.4)

plot(Basins_IMBIE,add=T)
plot(Coastline,add=T)

plot(fishgrid,add=T)

```



## Sensitivity test for Roughness and data density

```{r, echo=TRUE, fig.width=12, fig.height=6}

Kernel <- raster("Kernel_BM.tif")


sdata <- data.frame(TP_example,extract(Kernel,TP_example))


sdata$Label <- as.factor(sdata$Label)


col.pal <- c("blue","red")

sdata_0 <- subset(sdata, Label == 0 )
sdata_1 <- subset(sdata, Label == 1 )

p1<-ggplot(sdata, aes(x= sdata[,length(fs)],fill=Label)) +
          geom_density(position="identity", alpha=0.6)+
          scale_fill_manual(labels = c("Crystaline\nBasement", "Sedimentary\nBasin"),values = col.pal) +
          scale_x_continuous(name = "Re_Topo_STD")+
          theme(legend.position = c(0.8, 0.8),legend.title = element_blank())

p2<-ggplot(sdata, aes(x= sdata[,length(fs)+5],fill=Label)) +
          geom_density(position="identity", alpha=0.6)+
          scale_fill_manual(labels = c("Crystaline\nBasement", "Sedimentary\nBasin"),values = col.pal) +
          scale_x_continuous(name = "Kernel Density")+
          theme(legend.position='none')

p3<-ggplot(sdata_0) +
  aes(x = extract.Kernel..TP_example., y = Rebound_Topo_STD) +
  geom_bin2d() +
  scale_fill_continuous(type = "viridis",limits = c(0, 20)) +
  theme_bw() +
    xlim(0, 1) +
  ylim(0, 1500) +
  labs(title = "Crystaline Basement",x = "Kernel Density", y="Re_Topo_STD")
  

p4<-ggplot(sdata_1) +
  aes(x = extract.Kernel..TP_example., y = Rebound_Topo_STD) +
  geom_bin2d() +
  scale_fill_continuous(type = "viridis",limits = c(0, 20)) +
  theme_bw()+
  xlim(0, 1) +
  ylim(0, 1500) +
  labs(title = "Sedimentary Basin",x = "Kernel Density", y="Re_Topo_STD")
ggarrange(p1, p2, p3, p4, ncol = 2,nrow = 2)

```

Calculate the corrolation between data density and roughness

```{r ,echo=TRUE}

# Load data


sdata_0 <- subset(sdata, Label == 0 )
sdata_1 <- subset(sdata, Label == 1 )


x <- sdata[,c(length(fs),length(fs)+5)]
x0 <- sdata[,c(length(fs),length(fs)+5)]
x1 <- sdata[,c(length(fs),length(fs)+5)]

x <- na.omit(x) #drop nan value
x0 <- na.omit(x0) #drop nan value
x1 <- na.omit(x1) #drop nan value

Matrix_x <- matrix(unlist(x), ncol = 2, nrow = 1226)
Matrix_x0 <- matrix(unlist(x0), ncol = 2, nrow = 613)
Matrix_x1 <- matrix(unlist(x1), ncol = 2, nrow = 613)

Matrix_x <- na.omit(Matrix_x)
Matrix_x0 <- na.omit(Matrix_x0)
Matrix_x1 <- na.omit(Matrix_x1)

M <- mine(Matrix_x,alpha=0.7)
M0 <- mine(Matrix_x0,alpha=0.7)
M1 <- mine(Matrix_x1,alpha=0.7)

corR <- M$MIC
corR0 <- M0$MIC
corR1 <- M1$MIC

rownames(corR) <- colnames(x)
colnames(corR) <- colnames(x)


print(corR)

print(corR0)

print(corR1)

```


## Evidence layer selection

### Boruta for Evidence importance

```{r ,echo=TRUE}


TP_example_ngeo <- st_as_sf(TP_example)
TP_example_ngeo <- st_set_geometry(TP_example_ngeo, NULL) #remove geometry

TP_example_ngeo <- na.omit(TP_example_ngeo)

B1 <- Boruta(as.factor(Label)~., data = TP_example_ngeo, pValue=0.5, maxRuns=500)


print(B1)

par(mar=c(13,4,1,1), cex = 0.6)

plot(B1, las=2, colCode = c("greenyellow", "yellow2", "red3", "cadetblue"), xlab = "")

BorImp <- attStats(B1)[,c(1,6)]
BorImp <- subset(BorImp, decision == "Confirmed")
BorImp$Var <- rownames(BorImp)
rownames(BorImp) <- NULL
BorList <- list(BorImp[order(BorImp[1],decreasing=T),c(3,1)])

BorList


```

### MIC for Evidence correlation analysis


```{r ,echo=TRUE}

# Load data

TP_example_2 <- TP_example[, BorList[[1]][[1]]]

TB_drio <- na.omit(TP_example_2) #drop nan value

x <- TB_drio

XX <- st_as_sf(x)

XX <- st_set_geometry(XX, NULL) #remove geometry

Matrix_x <- matrix(unlist(XX), ncol = length(fs), nrow = 1226)

Matrix_x <- na.omit(Matrix_x)

M2 <- mine(Matrix_x,alpha=0.7)

corR2 <- M2$MIC

rownames(corR2) <- colnames(XX)

colnames(corR2) <- colnames(XX)

```

### Selected Evidence Layer

Relationship pf RF out of bag score vs MIC corrolation

```{r ,echo=TRUE}

seed <- 222

df_total <- data.frame()

for (i in c(10:100)*0.01) {
r <- i

cr <- corR2

for(j in 1:length(cr[1,])){
  if (j == 1){
    pl <- c(names(cr[j,][1]),names( cr[j,][sqrt((cr[j,])^2)<r]))
    pl1 <- pl
  } else if (names(cr[j,])[j] %in% pl1){
    rem <- names(cr[j,-c(1:j)][sqrt((cr[j,-c(1:j)])^2)>r])
    if (length(rem) != 0L){  
      pl <- pl[!pl %in% rem]
    }
  }
  next
}

clms <- c(names(TP_example_ngeo[1]),pl)
seldata <- TP_example_ngeo[clms]

set.seed(seed)
seldata$Label = factor(seldata$Label)
fit <- randomForest(Label ~ ., data=seldata)
df <- data.frame(i, length(pl), fit$err.rate[nrow(fit$err.rate),1])
df_total <- rbind(df_total,df)
}

names(df_total)[2] <- "Npreds"
names(df_total)[3] <- "OOBerror"

max(df_total$OOBerror) - min(df_total$OOBerror)


ggplot(df_total,aes(i,OOBerror)) + geom_point(aes(size=Npreds)) +
  xlab("MIC") + ylab("OOB error ") +geom_point(aes(x=0.55,y=0.2177814),colour="red")


```

ggplot(df_total,aes(i,OOBerror)) + geom_point(aes(size=Npreds)) +
  xlab("MIC") + ylab("OOB error ") +geom_point(aes(x=0.55,y=0.2177814),colour="red")



df_total

Selected evidence layer with MIC value


```{r ,echo=TRUE,fig.width=6, fig.height=6}
r <- 0.55

cr <- corR2

for(j in 1:length(cr[1,])){
  if (j == 1){
    pl <- c(names(cr[j,][1]),names( cr[j,][sqrt((cr[j,])^2)<r]))
    pl1 <- pl
  } else if (names(cr[j,])[j] %in% pl1){
    rem <- names(cr[j,-c(1:j)][sqrt((cr[j,-c(1:j)])^2)>r])
    if (length(rem) != 0L){  
      pl <- pl[!pl %in% rem]
    }
  }
  next
}

Npreds <- nrow(as.data.frame(pl))
clms <- c(names(TP_example_ngeo[1]),pl)
seldata <- TP_example_ngeo[clms]
sel.preds3 <- subset(Predp.stark,pl)


corrplot.mixed(corR2[pl,pl], lower.col =  "black", tl.pos = "l", tl.cex=0.7,number.cex = 0.5,is.corr = FALSE)


```




## RF parameyer turning

```{r message=FALSE, warning=FALSE, error=FALSE}

bindingIsLocked("params", env = .GlobalEnv)
unlockBinding("params", env = .GlobalEnv)
params$stuff <- 'toto'

train.control <- trainControl(method = "cv", number = 10 ,classProbs=T,
                     savePredictions = T)

tp_nb <- st_as_sf(TP_example[clms], NULL) #remove geometry


tp_ngeo <- st_set_geometry(tp_nb, NULL) #remove geometry


  
tp_ngeo$Label <- as.factor(tp_ngeo$Label)

tp_ngeo <- na.omit(tp_ngeo)

#ntree: Number of trees to grow.
tuneGrid <- expand.grid(.mtry = c(seq(2, length(clms)-1, by = 2)))

ntrees <- c(seq(400, 1000, by = 100))
  

params <- expand.grid(ntrees = ntrees)



control <- trainControl(method='repeatedcv', 
                        number=10, 
                        search = 'grid',
                        repeats=3)

#Random generate 15 mtry values with tuneLength = 15
set.seed(1)
store_acc <- list()
for(i in 1:nrow(params)){
  ntree <- params[i,1]
  set.seed(65)
  rf_model <- train(Label~.,
                       data = tp_ngeo,
                       method = "rf",
                    metric = 'Accuracy',
                    tuneGrid = tuneGrid,
                       trControl = control,
                       ntree = ntree)
  acc_tree <- cbind(rf_model$result[1:2],ntree)
  store_acc <- rbind(store_acc,acc_tree)

  }


summary(store_acc)

```
Plot the Model accuracy with ntree and mtry


```{r ,echo=TRUE}
mtry <- c(seq(2, length(clms)-1, by = 2))

ntrees <- c(seq(400, 1000, by = 100))

aa <- matrix(unlist(store_acc$Accuracy), ncol = 7, nrow = length(mtry))


image.plot(mtry,ntrees,aa,col=viridis(31))

mtry_f=which(aa == max(aa), arr.ind = TRUE)[1]*2

ntrees_f=400+(which(aa == max(aa), arr.ind = TRUE)[2]-1)*100

points(mtry_f,ntrees_f)

```


# Build RF model

## RF model 


```{r ,fig.width=6, fig.height=6 ,echo=TRUE, include=FALSE}

seed_all=c(1,2,3,4,5,6,7,8,9,10)

SSB_Probalility_Fishnet <- sample_training(Train_select,sel.preds3,fishgrid,mtry_f,ntrees_f,1,10,seed_all)

```


## Model Result

```{r, echo=TRUE, fig.width=6, fig.height=6}
mycols <- colors()[c(44,62,29,30,261,137,94,93,76,653)]

scolor <- c("#313694","#4576B6","#76ADD2","#AAD8E9","#DFF3F8","#FFE692","#FDAF60","#F66C42","#D73227","#A60324")

SSB_Probalility <- SSB_Probalility_Fishnet


aver_ppb <- sum(SSB_Probalility$Probalility)/10


plot(aver_ppb, col=scolor, breaks = c(0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1),xlab="X/m", ylab="Y/m", asp=1,main = "Average SSB Likelihood with 10 subsampling" )
plot(Basins_IMBIE,add=T)
plot(Coastline,add=T)


```


```{r}

writeRaster(aver_ppb, "SSB_Likelihood_F", bylayer=TRUE, format="GTiff",overwrite=T)

```

## Importance of Evidence layer

```{r, echo=TRUE}


Evidence <- row.names(SSB_Probalility_Fishnet$importance)

Im <- data.frame(SSB_Probalility_Fishnet$importance,rowSums(SSB_Probalility_Fishnet$importance)) 

col=colors()[c(44,62,29,30,261,137,94,93,76,653)]

ggplot(Im,aes(reorder(Evidence,rowSums.SSB_Probalility_Fishnet.importance.))) +
geom_point(aes(y=MeanDecreaseAccuracy),colour = col[1],size = 2) +
geom_point(aes(y=MeanDecreaseAccuracy.1),colour = col[2],size = 2) +
geom_point(aes(y=MeanDecreaseAccuracy.2),colour = col[3],size = 2) +
geom_point(aes(y=MeanDecreaseAccuracy.3),colour = col[4],size = 2) +
geom_point(aes(y=MeanDecreaseAccuracy.4),colour = col[5],size = 2) +
geom_point(aes(y=MeanDecreaseAccuracy.5),colour = col[6],size = 2) +
geom_point(aes(y=MeanDecreaseAccuracy.6),colour = col[7],size = 2) +
geom_point(aes(y=MeanDecreaseAccuracy.7),colour = col[8],size = 2) +
geom_point(aes(y=MeanDecreaseAccuracy.8),colour = col[9],size = 2) +
geom_point(aes(y=MeanDecreaseAccuracy.9),colour = col[10],size = 2) +

theme(axis.text.x=element_text(angle=45,hjust=1,vjust=1))

```

##  Model Performance and uncertainty

### Confusion matrix in each RF model

```{r, echo=TRUE}

Bcv.all_s <- SSB_Probalility_Fishnet$blockCV

acc_s <- confusionMatrix(Bcv.all_s$pred,as.factor(Bcv.all_s$Label))


print(acc_s)

```

### Confusion matrix for use all training points

```{r, echo=TRUE}

TP_10 <- SSB_Probalility_Fishnet$TP

TP_ALL <- TP_10[1:3]

for (i in 2:10) {

TP_sub_sample <- TP_10[c(3*(i-1)+1):c(3*i)]

colnames(TP_sub_sample)[c(1,2,3)] <- c("Label", "x","y")

TP_ALL <- rbind(TP_ALL,TP_sub_sample)

}

sdata_cv <- data.frame(TP_ALL[,2:3],extract(sel.preds3,TP_ALL[,2:3]))

sdata_cv<-cbind(TP_ALL[1], sdata_cv)

names(sdata_cv)[2] <- "x"

names(sdata_cv)[3] <- "y"

TP <- st_as_sf(sdata_cv, coords = c("x", "y"), crs = 3031) 

TP.s <- as(TP, "Spatial")

tp_ngeo <- st_set_geometry(TP, NULL) #remove geometry


#Perform Block Cross Validation
block.C2 <- spatialBlock(speciesData = TP.s, # sf or SpatialPoints
                   species = "label", # the response column (binomial or multi-class)
                   rows = 10,
                   cols = 10,
                   k = 10, # number of folds
                   selection = "random")  


                   
folds <- block.C2$folds

Nclasses <- c(2L)

class <- c("0","1")

classes <- c("Basement","SSB")
  
# create a data.frame to store the prediction of each fold (record)

testTable <- tp_ngeo
testTable$pred <- NA

t <- data.frame()

for(k in seq_len(length(folds))){
  
  # extracting the training and testing indices
  # this way works with folds list (but not foldID)
  trainSet <- unlist(folds[[k]][1]) # training set indices
  
  testSet <- unlist(folds[[k]][2]) # testing set indices
  
  sub_train <- tp_ngeo[trainSet, ]
  
  sub_train$Label <- as.factor(sub_train$Label)
    
  sub_test <- tp_ngeo[testSet, ]
  
  nnmin <- min(table(sub_train[1]))
  
  rf <- randomForest(Label~., data=sub_train, replace = T, mtry=mtry_f, ntree=ntrees_f, na.action = na.roughfix) # model fitting on training set
  
  pred <- predict(rf, sub_test, type = "response",na.action = na.roughfix) # predict the test set
  
  t <- rbind(t, data.frame(sub_test[1], pred, sdata_cv[testSet,2:3]))
  
}


acc <- confusionMatrix(t$pred,as.factor(t$Label))

name <- paste("T", k, sep = "")

tmp <- list(conf=acc)
  
bcv.acc <- tmp

bcv.acc

```


```{r, echo=TRUE, fig.width=12, fig.height=12}

Test.all <- data.frame(t)
Test.all$Res1[Test.all$Label == 1] <- 1
Test.all$Res1[Test.all$Label == 0] <- 0
Test.all$Res2[Test.all$pred == 1] <- 1
Test.all$Res2[Test.all$pred == 0] <- 0
Test.all$ResL <- Test.all$Res1 - Test.all$Res2


Wrong_class <- st_as_sf(Test.all, coords = c("x", "y"), crs = 3031) 

Wrong_class <- Wrong_class[5]

Wrong_class <- as(Wrong_class, "Spatial")

plot(x=NULL,
      y=NULL,
      xlim=c(-2705000, 2815000),  ## with c()
      ylim=c(-2315000, 2215000),xlab="X/m", ylab="Y/m",main="Incorrect classification during block CV",
      asp=1)  ## with c()



plot(Train_Basement,add=T,col="blue")
plot(Train_SSB,add=T,col="red")
plot(Basins_IMBIE,add=T)


points(Wrong_class[Wrong_class$ResL==-1,], pch = 16, col="magenta",cex = 0.6)

points(Wrong_class[Wrong_class$ResL==1,], pch = 16, col="yellow",cex = 0.6)


legend("topright",
       legend = c('Label:Basement', 'Incorrect:Basement', 'Label:Sedimentary Basin', 'Incorrect:Sedimentary Basin'),
       fill = c("blue","magenta","red","yellow"),       # Color of the squares
       border = "black") # Color of the border of the squares

plot(Coastline,add=T)


```


### Misclassification during block-cv

```{r, echo=TRUE, fig.width=12, fig.height=12}

Test.all <- data.frame(SSB_Probalility_Fishnet$blockCV)
Test.all$Res1[Test.all$Label == "SSB"] <- 1
Test.all$Res1[Test.all$Label == "Basement"] <- 0
Test.all$Res2[Test.all$pred == "SSB"] <- 1
Test.all$Res2[Test.all$pred == "Basement"] <- 0
Test.all$ResL <- Test.all$Res1 - Test.all$Res2

Test.all <- na.omit(Test.all)


Wrong_class <- st_as_sf(Test.all, coords = c("x", "y"), crs = 3031) 

Wrong_class <- Wrong_class[5]

Wrong_class <-  subset(Wrong_class, ResL != 0)

Wrong_class <- as(Wrong_class, "Spatial")

plot(x=NULL,
      y=NULL,
      xlim=c(-2705000, 2815000),  ## with c()
      ylim=c(-2315000, 2215000),xlab="X/m", ylab="Y/m",main="Incorrect classification during block CV",
      asp=1)  ## with c()



plot(Train_Basement,add=T,col="blue")
plot(Train_SSB,add=T,col="red")
plot(Basins_IMBIE,add=T)


points(Wrong_class[Wrong_class$ResL==-1,], pch = 16, col="magenta",cex = 0.6)

points(Wrong_class[Wrong_class$ResL==1,], pch = 16, col="yellow",cex = 0.6)

legend("topright",
       legend = c('Label:Basement', 'Incorrect:Basement', 'Label:Sedimentary Basin', 'Incorrect:Sedimentary Basin'),
       fill = c("blue","magenta","red","yellow"),       # Color of the squares
       border = "black") # Color of the border of the squares

plot(Coastline,add=T)


```


### Model result vs initial training polygon


```{r, echo=TRUE, fig.width=12, fig.height=12}

Train_compare <- raster('Initial_TP_8.tif')


Train_compare <- reclassify(Train_compare, c(1.1,2.2,0))


respond_1 <- reclassify(aver_ppb, c(0,0.4999,0,  0.5,1,1))


differ_respond=respond_1-Train_compare


print(freq(differ_respond))

plot(differ_respond, col=scico(3, palette = 'vik'), xlab="X/m",  asp=1, main = "Difference between model result and training information",legend=FALSE )
plot(Basins_IMBIE,add=T)

plot(Coastline,add=T)

legend("topright",
       legend = c('Label:SSB; Classified: Crystaline Bedrock ', 'Unchange','Label:Crystaline Bedrock; Classified: SSB ' ),
       fill = c(scico(3, palette = 'vik')),       # Color of the squares
       border = "black") # Color of the border of the squares

```




### Likelihood variation

```{r, echo=TRUE, fig.width=12, fig.height=12}
par(mfrow=c(2,2))    # set the plotting area into a 1*2 array
mycols <- colors()[c(44,62,29,30,261,137,94,93,76,653)]

scolor <- c("#313694","#4576B6","#76ADD2","#AAD8E9","#DFF3F8","#FFE692","#FDAF60","#F66C42","#D73227","#A60324")

SSB_Probalility <- SSB_Probalility_Fishnet

max_1 <- max(SSB_Probalility$Probalility)
min_1 <- min(SSB_Probalility$Probalility)
std_1 <- calc(SSB_Probalility$Probalility, sd)
reso_1 <- sum(SSB_Probalility$fress)


plot(max_1, col=scolor, breaks = c(0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1),xlab="X/m", ylab="Y/m", asp=1,main = "Max SSB Likelihood with 10 subsampling" )
plot(Basins_IMBIE,add=T)
plot(Coastline,add=T)

plot(min_1, col=scolor, breaks = c(0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1),xlab="X/m", ylab="Y/m", asp=1, main = "Min SSB Likelihood with 10 subsampling" )
plot(Basins_IMBIE,add=T)
plot(Coastline,add=T)


plot(std_1, col=viridis(21),xlab="X/m", ylab="Y/m", asp=1, main = "STD of SSB likelihood with 10 subsampling" )
plot(Basins_IMBIE,add=T)
plot(Coastline,add=T)


plot(reso_1, col=mycols,breaks = c(0,1,2,3,4,5,6,7,8,9,10),xlab="X/m", ylab="Y/m", asp=1, main = "SSB distribution with 10 subsampling" )
plot(Basins_IMBIE,add=T)
plot(Coastline,add=T)

```

### Misclassification vs STD of subRF model


```{r, echo=TRUE, fig.width=12, fig.height=12}



Test.all <- data.frame(SSB_Probalility_Fishnet$blockCV)
Test.all$Res1[Test.all$Label == "SSB"] <- 1
Test.all$Res1[Test.all$Label == "Basement"] <- 0
Test.all$Res2[Test.all$pred == "SSB"] <- 1
Test.all$Res2[Test.all$pred == "Basement"] <- 0
Test.all$ResL <- Test.all$Res1 - Test.all$Res2

Test.all <- na.omit(Test.all)


Wrong_class <- st_as_sf(Test.all, coords = c("x", "y"), crs = 3031) 

Wrong_class <- Wrong_class[5]

Wrong_class <- as(Wrong_class, "Spatial")

STD_P <- Wrong_class

sdata <- data.frame(STD_P,extract(std_1,STD_P))

names(sdata) <- c("Respond","x","y","o","STD")



sdata$Respond[abs(sdata$Respond)<0.5] <- 0

sdata$Respond[abs(sdata$Respond)>=0.5] <- 1


sdata$Respond <- as.factor(sdata$Respond)

sdata_1 <-  subset(sdata,Respond == 1)



col.pal <- c("blue","red")


p1<- ggplot(sdata_1,aes(x, y, color=STD)) + 
  geom_point(size = 0.5)+
  scale_colour_gradientn(colours=viridis(21))+
  theme(legend.position = c(0.1, 0.2))+
  labs(title = "a")

p2<-ggplot(sdata, aes(x= sdata[,5],fill=Respond)) +
          geom_density(position="identity", alpha=0.4)+
          geom_boxplot(position="identity", alpha=0.8,outlier.shape = NA) +
          scale_fill_manual(labels = c("Consistent", "Inconsistent"),values = col.pal) +
          scale_x_continuous(name = "STD")+
          theme(legend.position = c(0.8, 0.8),legend.title = element_blank())+
          labs(title = "b")


p <- rasterToPoints(differ_respond)
tpp <- data.frame(p)
p_select <- tpp

p_select$layer[abs(tpp$layer)<0.5] <- 0

p_select$layer[abs(tpp$layer)>=0.5] <- 1


p_select <- st_as_sf(p_select, coords = c("x", "y"), crs = 3031) 

p_select <- as_Spatial(p_select)

ssdata <- data.frame(p_select,extract(std_1,p_select))

names(ssdata) <- c("Respond","x","y","o","STD")


ssdata$Respond <- as.factor(ssdata$Respond)

ssdata_1 <-  subset(ssdata,Respond == 1)


col.pal <- c("blue","red")


p3<- ggplot(ssdata_1,aes(x, y, color=STD)) + 
  geom_point(size = 0.5)+
  scale_colour_gradientn(colours=viridis(21))+
  theme(legend.position = c(0.1, 0.2))+
  labs(title = "c")


p4<-ggplot(ssdata, aes(x= ssdata[,5],fill=Respond)) +
          geom_density(position="identity", alpha=0.4)+
          geom_boxplot(position="identity", alpha=0.8,outlier.shape = NA) +
          scale_fill_manual(labels = c("Consistent", "Inconsistent"),values = col.pal) +
          scale_x_continuous(name = "STD")+
          theme(legend.position = c(0.8, 0.8),legend.title = element_blank())+
          labs(title = "d")

ggarrange(p1, p2,p3,p4, ncol = 2,nrow = 2)

```




## Sensitivity test by shift reference fishnet 

```{r ,fig.width=6, fig.height=6 ,echo=TRUE, include=FALSE}

seed_all=c(1,2,3,4,5,6,7,8,9,10)

SSB_Probalility_Fishnet_shift <- sample_training(Train_select,sel.preds3,fishgrids,mtry_f,ntrees_f,1,10,seed_all)

```



## Model Result

```{r, echo=TRUE, fig.width=6, fig.height=6}
mycols <- colors()[c(44,62,29,30,261,137,94,93,76,653)]

scolor <- c("#313694","#4576B6","#76ADD2","#AAD8E9","#DFF3F8","#FFE692","#FDAF60","#F66C42","#D73227","#A60324")

SSB_Probalility <- SSB_Probalility_Fishnet_shift


aver_ppb_s <- sum(SSB_Probalility$Probalility)/10


plot(aver_ppb, col=scolor, breaks = c(0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1),xlab="X/m", ylab="Y/m", asp=1,main = "Average SSB Likelihood of 10 subRF model" )
plot(Basins_IMBIE,add=T)
plot(Coastline,add=T)


```


```{r, echo=TRUE, fig.width=14, fig.height=6}


differ_aver=aver_ppb-aver_ppb_s

respond_1 <- reclassify(aver_ppb, c(0,0.4999,0,  0.5,1,1))

respond_2 <- reclassify(aver_ppb_s, c(0,0.4999,0,  0.5,1,1))

differ_respond=respond_1-respond_2

par(mfrow=c(1,2))    # set the plotting area into a 1*2 array


plot(differ_aver, col=scico(21, palette = 'vik'), zlim = c(-0.5,0.5), xlab="X/m", ylab="Y/m", asp=1, main = "Difference of mean likelihood by shift fishnet" )

plot(Basins_IMBIE,add=T)

plot(Coastline,add=T)


plot(differ_respond, col=scico(3, palette = 'vik'), xlab="X/m",  asp=1, main = "Difference of model respond by shift fishnet" )

plot(Basins_IMBIE,add=T)

plot(Coastline,add=T)

```

```{r}

writeRaster(aver_ppb_s, "SSB_likelihood_Shift", bylayer=TRUE, format="GTiff",overwrite=T)

```